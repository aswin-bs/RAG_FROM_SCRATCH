{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-readers-file in ./.venv/lib/python3.10/site-packages (0.1.30)\n",
      "Requirement already satisfied: pymupdf in ./.venv/lib/python3.10/site-packages (1.24.7)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./.venv/lib/python3.10/site-packages (from llama-index-readers-file) (4.12.3)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.37.post1 in ./.venv/lib/python3.10/site-packages (from llama-index-readers-file) (0.10.56)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in ./.venv/lib/python3.10/site-packages (from llama-index-readers-file) (4.3.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./.venv/lib/python3.10/site-packages (from llama-index-readers-file) (0.0.26)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.6 in ./.venv/lib/python3.10/site-packages (from pymupdf) (1.24.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.5)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.6.1)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.36.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (4.0.3)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.5.15)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.3.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.0.5)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-index-vector-stores-postgres in ./.venv/lib/python3.10/site-packages (0.1.12)\n",
      "Requirement already satisfied: asyncpg<0.30.0,>=0.29.0 in ./.venv/lib/python3.10/site-packages (from llama-index-vector-stores-postgres) (0.29.0)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.20 in ./.venv/lib/python3.10/site-packages (from llama-index-vector-stores-postgres) (0.10.56)\n",
      "Requirement already satisfied: pgvector<0.3.0,>=0.2.4 in ./.venv/lib/python3.10/site-packages (from llama-index-vector-stores-postgres) (0.2.5)\n",
      "Requirement already satisfied: psycopg2-binary<3.0.0,>=2.9.9 in ./.venv/lib/python3.10/site-packages (from llama-index-vector-stores-postgres) (2.9.9)\n",
      "Requirement already satisfied: sqlalchemy<2.1,>=1.4.49 in ./.venv/lib/python3.10/site-packages (from sqlalchemy[asyncio]<2.1,>=1.4.49->llama-index-vector-stores-postgres) (2.0.31)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in ./.venv/lib/python3.10/site-packages (from asyncpg<0.30.0,>=0.29.0->llama-index-vector-stores-postgres) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.6.1)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.36.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from sqlalchemy<2.1,>=1.4.49->sqlalchemy[asyncio]<2.1,>=1.4.49->llama-index-vector-stores-postgres) (3.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.9.4)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.5.15)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.3.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.0.5)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in ./.venv/lib/python3.10/site-packages (0.2.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.24.0)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in ./.venv/lib/python3.10/site-packages (from llama-index-embeddings-huggingface) (0.10.56)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in ./.venv/lib/python3.10/site-packages (from llama-index-embeddings-huggingface) (3.0.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.5)\n",
      "Requirement already satisfied: minijinja>=1.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.31)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.36.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (10.4.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./.venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.42.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.5.15)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.5)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.0.3)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.5.82)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index-llms-llama-cpp\n",
      "  Using cached llama_index_llms_llama_cpp-0.1.4-py3-none-any.whl.metadata (695 bytes)\n",
      "Requirement already satisfied: llama-cpp-python<0.3.0,>=0.2.32 in ./.venv/lib/python3.10/site-packages (from llama-index-llms-llama-cpp) (0.2.82)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in ./.venv/lib/python3.10/site-packages (from llama-index-llms-llama-cpp) (0.10.56)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in ./.venv/lib/python3.10/site-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in ./.venv/lib/python3.10/site-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in ./.venv/lib/python3.10/site-packages (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (3.1.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2024.6.1)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.8.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.36.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (4.66.4)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp) (2.1.5)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2024.5.15)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.3.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.0.5)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp) (1.16.0)\n",
      "Using cached llama_index_llms_llama_cpp-0.1.4-py3-none-any.whl (6.0 kB)\n",
      "Installing collected packages: llama-index-llms-llama-cpp\n",
      "Successfully installed llama-index-llms-llama-cpp-0.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-readers-file pymupdf\n",
    "%pip install llama-index-vector-stores-postgres\n",
    "%pip install llama-index-embeddings-huggingface\n",
    "%pip install llama-index-llms-llama-cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aswin/Desktop/GIT/llama_rag/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# sentence transformers\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in ./.venv/lib/python3.10/site-packages (0.2.82)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in ./.venv/lib/python3.10/site-packages (from llama-cpp-python) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in ./.venv/lib/python3.10/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in ./.venv/lib/python3.10/site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /tmp/llama_index/models/llama-2-7b-chat.Q4_0.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_0:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens cache size = 259\n",
      "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.56 GiB (4.54 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  3647.87 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 3904\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1952.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1952.00 MiB, K (f16):  976.00 MiB, V (f16):  976.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   283.63 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '2'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "\n",
    "# model_url = \"https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q4_0.bin\"\n",
    "model_url = \"https://huggingface.co/TheBloke/Llama-2-7B-chat-GGUF/resolve/main/llama-2-7b-chat.Q4_0.gguf\"\n",
    "\n",
    "llm = LlamaCPP(\n",
    "   \n",
    "    model_url=model_url,\n",
    "    model_path=None,\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=256,\n",
    " \n",
    "    context_window=3900,\n",
    "\n",
    "    generate_kwargs={},\n",
    "\n",
    "    # set to at least 1 to use GPU\n",
    "    model_kwargs={\"n_gpu_layers\": 1},\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in ./.venv/lib/python3.10/site-packages (2.9.9)\n",
      "Requirement already satisfied: pgvector in ./.venv/lib/python3.10/site-packages (0.2.5)\n",
      "Requirement already satisfied: asyncpg in ./.venv/lib/python3.10/site-packages (0.29.0)\n",
      "Requirement already satisfied: greenlet in ./.venv/lib/python3.10/site-packages (3.0.3)\n",
      "Requirement already satisfied: sqlalchemy[asyncio] in ./.venv/lib/python3.10/site-packages (2.0.31)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from pgvector) (1.26.4)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in ./.venv/lib/python3.10/site-packages (from asyncpg) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./.venv/lib/python3.10/site-packages (from sqlalchemy[asyncio]) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary pgvector asyncpg \"sqlalchemy[asyncio]\" greenlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "db_name = \"vector_db\"\n",
    "host = \"localhost\"\n",
    "password = \"2310\"\n",
    "port = \"5432\"\n",
    "user = \"postgres\"\n",
    "# conn = psycopg2.connect(connection_string)\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    host=\"localhost\",\n",
    "    password=password,\n",
    "    port=port,\n",
    "    user=user,\n",
    ")\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn.cursor() as c:\n",
    "    c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "    c.execute(f\"CREATE DATABASE {db_name}\")\n",
    "    c.execute(f'GRANT CONNECT ON DATABASE {db_name} TO {user}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=\"localhost\",\n",
    "    password=password,\n",
    "    port=port,\n",
    "    user=user,\n",
    "    table_name=\"llama2_paper\",\n",
    "    embed_dim=384,  # openai embedding dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-20 17:41:30--  https://arxiv.org/pdf/2307.09288.pdf\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.131.42, 151.101.3.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://arxiv.org/pdf/2307.09288 [following]\n",
      "--2024-07-20 17:41:31--  http://arxiv.org/pdf/2307.09288\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13661300 (13M) [application/pdf]\n",
      "Saving to: ‘data/llama2.pdf’\n",
      "\n",
      "data/llama2.pdf     100%[===================>]  13.03M  2.15MB/s    in 13s     \n",
      "\n",
      "2024-07-20 17:41:45 (993 KB/s) - ‘data/llama2.pdf’ saved [13661300/13661300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import PyMuPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFReader()\n",
    "documents = loader.load(file_path=\"/home/aswin/Desktop/GIT/llama_rag/Research_Regulations-2023-1166-2023-KTU.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_parser = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    # separator=\" \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = []\n",
    "\n",
    "doc_idxs = []\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    cur_text_chunks = text_parser.split_text(doc.text)\n",
    "    text_chunks.extend(cur_text_chunks)\n",
    "    doc_idxs.extend([doc_idx] * len(cur_text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = []\n",
    "for idx, text_chunk in enumerate(text_chunks):\n",
    "    node = TextNode(\n",
    "        text=text_chunk,\n",
    "    )\n",
    "    src_doc = documents[doc_idxs[idx]]\n",
    "    node.metadata = src_doc.metadata\n",
    "    nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=\"all\")\n",
    "    )\n",
    "    node.embedding = node_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b5c19452-cce6-44eb-b051-7af5c451a905',\n",
       " '9f747596-3f9e-41b1-a73f-79ef8cd02492',\n",
       " 'efe12daf-27db-4e7d-90d1-02754112cf22',\n",
       " 'acc2c021-f6cc-4226-95ba-88895870722a',\n",
       " '978a9a52-c74d-43de-9a21-7ee629b847f4',\n",
       " '4c4f930c-60ef-43c9-9032-54c6a68cc092',\n",
       " '7fd9eadb-c764-4fa2-96b7-973a72b83a61',\n",
       " 'fa63ee0a-e82f-4ff3-be83-cb187df751eb',\n",
       " '6e99ea8d-c9ca-4432-83be-2413caf21e65',\n",
       " 'cdacdf96-9602-41ba-85a2-2ed9fb032729',\n",
       " 'b53cea05-397d-4cb4-9b02-602a8c0d181e',\n",
       " '4bed9870-047e-48f6-89d6-54b5ac62587f',\n",
       " 'd8b97f5e-fca1-42ee-ae35-75cfa8fb6260',\n",
       " '8361e18d-caf9-4dbf-a35c-87c52ab8552a',\n",
       " '0eab03c5-0683-49a3-91c2-1246575604f2',\n",
       " '8d43a757-e2c0-45fc-ab28-773de5599f6d',\n",
       " 'fb17aefb-bcb2-4c7e-9a68-d3ad6ab8fc48',\n",
       " '5b0eba2a-3ad4-44b0-a616-1fc6645a17fd']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"who  are eligible for admission to Ph. D.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embed_model.get_query_embedding(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "\n",
    "query_mode = \"default\"\n",
    "\n",
    "\n",
    "vector_store_query = VectorStoreQuery(\n",
    "    query_embedding=query_embedding, similarity_top_k=2, mode=query_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regulations for the award of the Degree of Doctor of Philosophy by the A P J\n",
      "Abdul Kalam Technological University 2023.\n",
      "(Revised as per the University Grants Commission (Minimum Standards and Procedures for Award\n",
      "of Ph.D. Degree) Regulations, 2022)\n",
      "1.\n",
      "Admission\n",
      "1.1\n",
      "Categories of Admission\n",
      "1.1.1\n",
      "There shall be TWO categories of Ph. D. admission as given below:\n",
      "(i)\n",
      "Full-time scholars with or without fellowship\n",
      "(ii) Part-time scholars in the following category admitted to pursue research towards Ph.\n",
      "D. degree while working.\n",
      "a.\n",
      "Faculty members of the University Departments \n",
      "b.\n",
      "Faculty members of affiliated colleges \n",
      "c.\n",
      "Persons working with Organisations / Industries within the Country \n",
      "1.2 \n",
      "Ph.D. through Part-time \n",
      "1.2.1 \n",
      "Ph.D. programmes through part-time will be permitted, provided all the conditions stipulated\n",
      "in the Regulations are fulfilled.\n",
      "1.2.3 \n",
      "The candidate shall produce a “No Objection Certificate” from the appointing authority in\n",
      "the organization where the candidate is employed, clearly stating that:\n",
      "(i)\n",
      "The candidate is permitted to pursue studies on a part-time basis.\n",
      "(ii)\n",
      "His/her official duties permit him/her to devote sufficient time for research.\n",
      "(iii)\n",
      "If  required,  he/she  will  be  relieved  from  the  duty  to  complete  the  academic\n",
      "requirements.\n",
      "2.\n",
      "Eligibility for admission\n",
      "2.1\n",
      "Candidates with the following qualifications are eligible for admission to Ph. D.\n",
      "(i)\n",
      "Master’s Degree in Engineering/ Technology, Architecture or a Master’s Degree by\n",
      "research in Engineering/ Technology with a minimum CGPA of 5.75.\n",
      "(ii)\n",
      "Master’s Degree in Basic Sciences or Mathematics with a minimum CGPA of 5.75.\n",
      "(iii)\n",
      "Master’s Degree in Computer Applications with a minimum CGPA of 5.75.\n",
      "(iv)\n",
      "For Ph.D. in Management, Master’s degree in Management with a minimum CGPA\n",
      "of 5.75 or equivalent Master’s degree in Engineering/Technology in Management\n",
      "related streams with a minimum CGPA of 5.75.\n",
      "(v)\n",
      "Bachelor’s degree in Engineering / Architecture with a minimum of 7.75 CGPA. \n",
      "2.2\n",
      "Scheduled Caste / Scheduled Tribe / Other Backward Community (Non-Creamy Layers) /\n",
      "Differently-abled category candidates (with more than 40% disability) / EWS are eligible for\n",
      "admission with a minimum CGPA of 5.25 in all cases (i) to (iv) above and CGPA of 7.25 for\n",
      "case (v). Certificate of disability issued by District Medical Board is to be produced in the\n",
      "case of differently-abled candidates.\n",
      "2.3\n",
      "Basic Sciences candidates are allowed to pursue full-time as well as part-time research on\n",
      "the condition that for all streams other than Mathematics, a Co-guide is mandatory from a\n",
      "1\n",
      "Page 3 of 18\n"
     ]
    }
   ],
   "source": [
    "# returns a VectorStoreQueryResult\n",
    "query_result = vector_store.query(vector_store_query)\n",
    "print(query_result.nodes[0].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "from typing import Optional\n",
    "\n",
    "nodes_with_scores = []\n",
    "for index, node in enumerate(query_result.nodes):\n",
    "    score: Optional[float] = None\n",
    "    if query_result.similarities is not None:\n",
    "        score = query_result.similarities[index]\n",
    "    nodes_with_scores.append(NodeWithScore(node=node, score=score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from typing import Any, List\n",
    "\n",
    "\n",
    "class VectorDBRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever over a postgres vector store.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_store: PGVectorStore,\n",
    "        embed_model: Any,\n",
    "        query_mode: str = \"default\",\n",
    "        similarity_top_k: int = 2,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        self._vector_store = vector_store\n",
    "        self._embed_model = embed_model\n",
    "        self._query_mode = query_mode\n",
    "        self._similarity_top_k = similarity_top_k\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve.\"\"\"\n",
    "        query_embedding = embed_model.get_query_embedding(\n",
    "            query_bundle.query_str\n",
    "        )\n",
    "        vector_store_query = VectorStoreQuery(\n",
    "            query_embedding=query_embedding,\n",
    "            similarity_top_k=self._similarity_top_k,\n",
    "            mode=self._query_mode,\n",
    "        )\n",
    "        query_result = vector_store.query(vector_store_query)\n",
    "\n",
    "        nodes_with_scores = []\n",
    "        for index, node in enumerate(query_result.nodes):\n",
    "            score: Optional[float] = None\n",
    "            if query_result.similarities is not None:\n",
    "                score = query_result.similarities[index]\n",
    "            nodes_with_scores.append(NodeWithScore(node=node, score=score))\n",
    "\n",
    "        return nodes_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = VectorDBRetriever(\n",
    "    vector_store, embed_model, query_mode=\"default\", similarity_top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  204988.22 ms\n",
      "llama_print_timings:      sample time =      34.33 ms /    57 runs   (    0.60 ms per token,  1660.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  766119.10 ms /  1941 tokens (  394.70 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:        eval time =   15256.38 ms /    56 runs   (  272.44 ms per token,     3.67 tokens per second)\n",
      "llama_print_timings:       total time =  781459.20 ms /  1997 tokens\n"
     ]
    }
   ],
   "source": [
    "query_str = \"who  are eligible for admission to Ph. D.\"\n",
    "\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Candidates with a Master’s degree in Engineering/Technology, Architecture or a Master’s degree by research in Engineering/Technology with a minimum CGPA of 5.75 are eligible for admission to Ph.D. programs.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regulations for the award of the Degree of Doctor of Philosophy by the A P J\n",
      "Abdul Kalam Technological University 2023.\n",
      "(Revised as per the University Grants Commission (Minimum Standards and Procedures for Award\n",
      "of Ph.D. Degree) Regulations, 2022)\n",
      "1.\n",
      "Admission\n",
      "1.1\n",
      "Categories of Admission\n",
      "1.1.1\n",
      "There shall be TWO categories of Ph. D. admission as given below:\n",
      "(i)\n",
      "Full-time scholars with or without fellowship\n",
      "(ii) Part-time scholars in the following category admitted to pursue research towards Ph.\n",
      "D. degree while working.\n",
      "a.\n",
      "Faculty members of the University Departments \n",
      "b.\n",
      "Faculty members of affiliated colleges \n",
      "c.\n",
      "Persons working with Organisations / Industries within the Country \n",
      "1.2 \n",
      "Ph.D. through Part-time \n",
      "1.2.1 \n",
      "Ph.D. programmes through part-time will be permitted, provided all the conditions stipulated\n",
      "in the Regulations are fulfilled.\n",
      "1.2.3 \n",
      "The candidate shall produce a “No Objection Certificate” from the appointing authority in\n",
      "the organization where the candidate is employed, clearly stating that:\n",
      "(i)\n",
      "The candidate is permitted to pursue studies on a part-time basis.\n",
      "(ii)\n",
      "His/her official duties permit him/her to devote sufficient time for research.\n",
      "(iii)\n",
      "If  required,  he/she  will  be  relieved  from  the  duty  to  complete  the  academic\n",
      "requirements.\n",
      "2.\n",
      "Eligibility for admission\n",
      "2.1\n",
      "Candidates with the following qualifications are eligible for admission to Ph. D.\n",
      "(i)\n",
      "Master’s Degree in Engineering/ Technology, Architecture or a Master’s Degree by\n",
      "research in Engineering/ Technology with a minimum CGPA of 5.75.\n",
      "(ii)\n",
      "Master’s Degree in Basic Sciences or Mathematics with a minimum CGPA of 5.75.\n",
      "(iii)\n",
      "Master’s Degree in Computer Applications with a minimum CGPA of 5.75.\n",
      "(iv)\n",
      "For Ph.D. in Management, Master’s degree in Management with a minimum CGPA\n",
      "of 5.75 or equivalent Master’s degree in Engineering/Technology in Management\n",
      "related streams with a minimum CGPA of 5.75.\n",
      "(v)\n",
      "Bachelor’s degree in Engineering / Architecture with a minimum of 7.75 CGPA. \n",
      "2.2\n",
      "Scheduled Caste / Scheduled Tribe / Other Backward Community (Non-Creamy Layers) /\n",
      "Differently-abled category candidates (with more than 40% disability) / EWS are eligible for\n",
      "admission with a minimum CGPA of 5.25 in all cases (i) to (iv) above and CGPA of 7.25 for\n",
      "case (v). Certificate of disability issued by District Medical Board is to be produced in the\n",
      "case of differently-abled candidates.\n",
      "2.3\n",
      "Basic Sciences candidates are allowed to pursue full-time as well as part-time research on\n",
      "the condition that for all streams other than Mathematics, a Co-guide is mandatory from a\n",
      "1\n",
      "Page 3 of 18\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
